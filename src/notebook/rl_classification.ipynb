{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.dqn.policies import MlpPolicy\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from datetime import datetime\n",
    "from torch import nn  # Import the neural network module from PyTorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.dqn.policies import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import sys\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "import os\n",
    "sys.path.append(os.path.join('..'))\n",
    "from classes._exploration import exploration\n",
    "from classes._Env3WGym import Env3WGym\n",
    "from classes._LoadInstances import LoadInstances\n",
    "from classes._Agent import Agent\n",
    "from classes._Supervised import Supervised\n",
    "from classes._ValidationModel import ValidationModel\n",
    "from classes._exploration import exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação dos dados simulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    events_names = {\n",
    "        # 0: 'Normal',\n",
    "        1: 'Abrupt Increase of BSW',\n",
    "        # 2: 'Spurious Closure of DHSV',\n",
    "        # 3: 'Severe Slugging',\n",
    "        # 4: 'Flow Instability',\n",
    "        # 5: 'Rapid Productivity Loss',\n",
    "        # 6: 'Quick Restriction in PCK',\n",
    "        # 7: 'Scaling in PCK',\n",
    "        # 8: 'Hydrate in Production Line'\n",
    "    }\n",
    "\n",
    "    event_name = [value for key, value in events_names.items() if key != 0][0]\n",
    "    \n",
    "    models = ['DQN' , 'PPO', 'A2C'] # 'DQN' , 'PPO', 'A2C', 'RNA'\n",
    "    type_instance= 'real' # real, simulated\n",
    "    path_dataset = '..\\\\..\\\\..\\\\dataset'\n",
    "    instances = LoadInstances(path_dataset)\n",
    "            \n",
    "    logging.info(f'Iniciando carregamento do dataset')\n",
    "    dataset, _ = instances.load_instance_with_numpy(events_names, type_instance=type_instance)    \n",
    "    logging.info(f'Fim carregamento do dataset')\n",
    "    \n",
    "    logging.info(f'Iniciando divisão do dataset em treino e teste')\n",
    "        \n",
    "    # Definindo a porcentagem para divisão entre treino e teste\n",
    "    train_percentage = 0.8  # 80% para treino\n",
    "\n",
    "    dataset_train_scaled, dataset_test_scaled, dataset_validation_scaled = instances.data_preparation(dataset, train_percentage)\n",
    "\n",
    "    env_train = Env3WGym(dataset_train_scaled, n_envs = 5)\n",
    "    env_test = Env3WGym(dataset_test_scaled, n_envs = 1)\n",
    "\n",
    "    envs_train = env_train.envs_random()\n",
    "    envs_test = env_test.envs_random()\n",
    "\n",
    "    path_tensorboard = f'..\\\\models\\\\{event_name}-{type_instance}'   \n",
    "    if not os.path.exists(path_tensorboard):\n",
    "                os.makedirs(path_tensorboard)\n",
    "\n",
    "    agente = Agent(path_tensorboard, envs_train, envs_test, TIMESTEPS = 100000)\n",
    "\n",
    "    list_timesteps = [1000, 10000, 100000, 150000, 300000]\n",
    "    \n",
    "    for model_type in models:\n",
    "        for event_name in [value for key, value in events_names.items() if key != 0]:\n",
    "\n",
    "            directory = f'..\\\\..\\\\logs\\\\{event_name}-{type_instance}'               \n",
    "            path_model = f'..\\\\models\\\\{event_name}-{type_instance}\\\\{model_type}'  \n",
    "\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            \n",
    "            if not os.path.exists(path_model):\n",
    "                os.makedirs(path_model)   \n",
    "                    \n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            log_filename = f'{directory}\\\\{current_time}_{event_name}-{type_instance}_{model_type}-log.txt'\n",
    "            # Configuração do Logging\n",
    "            logging.basicConfig(filename=log_filename, filemode='w', level=logging.INFO, format='[%(levelname)s]\\t%(asctime)s - %(message)s', datefmt='%d/%m/%Y %I:%M:%S %p', force=True, encoding='utf-8')\n",
    "          \n",
    "            logging.info(f'Iniciando a execução do algoritmo {model_type}-{type_instance} para o evento {event_name} com timesteps {agente.TIMESTEPS}')\n",
    "            \n",
    "\n",
    "            \n",
    "            if model_type == 'DQN':                \n",
    "                \n",
    "                for i in list_timesteps:\n",
    "                    agente.TIMESTEPS = i\n",
    "                    try:\n",
    "                        logging.info(f'Iniciando treinamento do algoritmo DQN {agente.TIMESTEPS} timesteps')    \n",
    "                        start_time = time.time()                \n",
    "                        model_agent, replaydir = agente.env3W_dqn(path_save=path_model)  \n",
    "                        print(f\"Tempo de Treinamento DQN: {round(time.time() - start_time, 2)}s\")\n",
    "                        logging.info(f\"Tempo de Treinamento DQN: {round(time.time() - start_time, 2)}s\")\n",
    "                        logging.info(f'Fim treinamento do algoritmo DQN')\n",
    "\n",
    "                        try:\n",
    "                            logging.info(f'Iniciando avaliação do algoritmo DQN conjunto de teste')\n",
    "                            accuracy = agente.env3W_dqn_eval(model = model_agent, path_save=path_model)\n",
    "                            print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando DQN')\n",
    "                            logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando DQN')\n",
    "                            logging.info(f'Fim avaliação  do algoritmo DQN conjunto de teste')\n",
    "                        except Exception as e:\n",
    "                            logging.error(f'Erro ao avaliar o modelo DQN: {e}')\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logging.error(f'Erro ao treinar o modelo DQN: {e}')\n",
    "                \n",
    "            elif model_type == 'PPO':      \n",
    "                \n",
    "                for i in list_timesteps:\n",
    "                    agente.TIMESTEPS = i\n",
    "                    logging.info(f'Iniciando treinamento do algoritmo PPO {agente.TIMESTEPS} timesteps') \n",
    "                    start_time = time.time()\n",
    "                    #agente = Agent(path_model)\n",
    "                    model_agent = agente.env3W_ppo(path_save=path_model)  \n",
    "                    print(f\"Tempo de Treinamento PPO: {round(time.time() - start_time, 2)}s\")\n",
    "                    logging.info(f\"Tempo de Treinamento PPO: {round(time.time() - start_time, 2)}s\")\n",
    "                    logging.info(f'Fim treinamento do algoritmo PPO')\n",
    "                                \n",
    "                    logging.info(f'Iniciando avaliação do algoritmo PPO conjunto de teste')\n",
    "                    accuracy = agente.env3W_ppo_eval(model = model_agent, path_save=path_model)\n",
    "                    print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando PPO')\n",
    "                    logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando PPO')\n",
    "                    logging.info(f'Fim avaliação  do algoritmo PPO conjunto de teste')\n",
    "               \n",
    "            elif model_type == 'A2C': \n",
    "\n",
    "                for i in list_timesteps:\n",
    "                    agente.TIMESTEPS = i                \n",
    "                    try:     \n",
    "                        logging.info(f'Iniciando treinamento do algoritmo A2C') \n",
    "                        start_time = time.time()\n",
    "                        #agente = Agent(path_model)\n",
    "                        model_agent = agente.env3W_a2c(path_save=path_model)  \n",
    "                        print(f\"Tempo de Treinamento A2C: {round(time.time() - start_time, 2)}s\")\n",
    "                        logging.info(f\"Tempo de Treinamento A2C: {round(time.time() - start_time, 2)}s\")\n",
    "                        logging.info(f'Fim treinamento do algoritmo A2C')\n",
    "                    \n",
    "                        try:\n",
    "                            logging.info(f'Iniciando avaliação do algoritmo A2C conjunto de teste')\n",
    "                            accuracy = agente.env3W_a2c_eval(model = model_agent, path_save=path_model)\n",
    "                            print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando A2C')\n",
    "                            logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando A2C')\n",
    "                            logging.info(f'Fim avaliação  do algoritmo A2C conjunto de teste')\n",
    "                        except Exception as e:\n",
    "                            logging.error(f'Erro ao avaliar o modelo A2C: {e}')\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logging.error(f'Erro ao treinar o modelo A2C: {e}')\n",
    "            \n",
    "            elif model_type == 'RNA':\n",
    "                try:\n",
    "                    logging.info(f'Iniciando treinamento do modelo RNA') \n",
    "                    dataset_train_scaled[:, -1] = np.where(dataset_train_scaled[:, -1] == 101, 1, dataset_train_scaled[:, -1])\n",
    "                    dataset_test_scaled[:, -1] = np.where(dataset_test_scaled[:, -1] == 101, 1, dataset_test_scaled[:, -1])\n",
    "                    supervised = Supervised(path_model, dataset_train_scaled, dataset_test_scaled)\n",
    "                    start_time = time.time()\n",
    "                    model_agent = supervised.keras_train()  \n",
    "                    print(f\"Tempo de Treinamento RNA: {round(time.time() - start_time, 2)}s\")\n",
    "                    logging.info(f\"Tempo de Treinamento RNA: {round(time.time() - start_time, 2)}s\")\n",
    "                    logging.info(f'Fim treinamento do modelo RNA')\n",
    "\n",
    "                    try:\n",
    "                        logging.info(f'Iniciando avaliação do modelo RNA conjunto de teste')\n",
    "                        accuracy = supervised.keras_evaluate(model_agent)\n",
    "                        print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando RNA')\n",
    "                        logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando RNA')\n",
    "                        logging.info(f'Fim avaliação  do modelo RNA conjunto de teste')\n",
    "                    except Exception as e:\n",
    "                        logging.error(f'Erro ao treinar o modelo RNA: {e}')\n",
    "                except Exception as e:\n",
    "                    logging.error(f'Erro ao treinar o modelo RNA: {e}')\n",
    "\n",
    "            #logging.info(f'Iniciando a validação do modelo {model_type}') \n",
    "            #validation = ValidationModel(model_type, event_name)\n",
    "            #validation.validation_model(accuracy, dataset_validation_scaled, model_agent)\n",
    "\n",
    "            logging.info(f'Concluído a execução do algoritmo {model_type}-{type_instance} para o evento {event_name}')\n",
    "            # Para fechar explicitamente o arquivo de log, obtenha todos os handlers do root logger e feche-os\n",
    "            for handler in logging.root.handlers[:]:\n",
    "                handler.close()\n",
    "                logging.root.removeHandler(handler)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação com dados reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    events_names = {\n",
    "        # 0: 'Normal',\n",
    "        1: 'Abrupt Increase of BSW',\n",
    "        # 2: 'Spurious Closure of DHSV',\n",
    "        # 3: 'Severe Slugging',\n",
    "        # 4: 'Flow Instability',\n",
    "        # 5: 'Rapid Productivity Loss',\n",
    "        # 6: 'Quick Restriction in PCK',\n",
    "        # 7: 'Scaling in PCK',\n",
    "        # 8: 'Hydrate in Production Line'\n",
    "    }\n",
    "\n",
    "    event_name = [value for key, value in events_names.items() if key != 0][0]\n",
    "    \n",
    "    models = ['DQN'] # 'DQN' \n",
    "    type_instance= 'real' # real, simulated\n",
    "    path_dataset = '..\\\\..\\\\..\\\\dataset'\n",
    "    instances = LoadInstances(path_dataset)\n",
    "    model_type = models[0]\n",
    "            \n",
    "    logging.info(f'Iniciando carregamento do dataset')\n",
    "    dataset, _ = instances.load_instance_with_numpy(events_names, type_instance=type_instance)    \n",
    "    logging.info(f'Fim carregamento do dataset')    \n",
    "    \n",
    "    logging.info(f'Iniciando divisão do dataset em treino e teste')        \n",
    "    # Definindo a porcentagem para divisão entre treino e teste\n",
    "    train_percentage = 0.8  # 80% para treino\n",
    "    dataset_train_scaled, dataset_test_scaled, dataset_validation_scaled = instances.data_preparation(dataset, train_percentage)\n",
    "   \n",
    "    env_train = Env3WGym(dataset_train_scaled, n_envs = 5)\n",
    "    env_test = Env3WGym(dataset_test_scaled, n_envs = 1)\n",
    "\n",
    "    envs_train = env_train.envs_random()\n",
    "    envs_test = env_test.envs_random()\n",
    "\n",
    "    env_test_cl = Env3WGym(dataset_test_scaled, n_envs = 5)\n",
    "    envs_cl = env_test_cl.envs_random()\n",
    "\n",
    "    directory = f'..\\\\..\\\\logs\\\\{event_name}-{type_instance}-CL'\n",
    "    path_dataset = '..\\\\..\\\\..\\\\dataset'   \n",
    "    path_model = f'..\\\\models\\\\{event_name}-{type_instance}\\\\{model_type}'  \n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    if not os.path.exists(path_model):\n",
    "        os.makedirs(path_model)    \n",
    "\n",
    "    path_tensorboard = f'..\\\\models\\\\{event_name}-{type_instance}-CL'   \n",
    "    if not os.path.exists(path_tensorboard):\n",
    "        os.makedirs(path_tensorboard)\n",
    "\n",
    "    agente = Agent(path_tensorboard, envs_train, envs_test, TIMESTEPS = 100000)            \n",
    "\n",
    "            \n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    log_filename = f'{directory}\\\\{current_time}_{event_name}-{type_instance}_{model_type}-log.txt'\n",
    "    # Configuração do Logging\n",
    "    logging.basicConfig(filename=log_filename, filemode='w', level=logging.INFO, \n",
    "                        format='[%(levelname)s]\\t%(asctime)s - %(message)s', \n",
    "                        datefmt='%d/%m/%Y %I:%M:%S %p', force=True, encoding='utf-8')\n",
    "   \n",
    "\n",
    "    if model_type == 'DQN':\n",
    "        \n",
    "        logging.info(f'Iniciando o teste do algoritmo DQN (Continual Learning)')    \n",
    "        #start_time = time.time()\n",
    "        #model_agent = agente.env3W_dqn(path_save=path_model)  \n",
    "        #print(f\"Tempo de Treinamento DQN: {round(time.time() - start_time, 2)}s\")\n",
    "        #logging.info(f\"Tempo de Treinamento DQN: {round(time.time() - start_time, 2)}s\")\n",
    "        #logging.info(f'Fim treinamento do algoritmo DQN')\n",
    "        \n",
    "\n",
    "        # Carrega o modelo treinado em simulação com 100k passos\n",
    "        path_model_zip = os.path.join(\"..\", \"models\", \"Abrupt Increase of BSW-simulated\", \"DQN\", \"_DQN.zip\")\n",
    "        \n",
    "        # Avalia o modelo treinado em simulação com 100k passos no ambiente real\n",
    "        model_agent = DQN.load(path_model_zip) \n",
    "        logging.info(f'Iniciando avaliação do algoritmo DQN conjunto de teste')\n",
    "        accuracy = agente.env3W_dqn_eval(model = model_agent, path_save=path_model)\n",
    "        print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando DQN')\n",
    "        logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando DQN')\n",
    "        logging.info(f'Fim avaliação  do algoritmo DQN conjunto de teste')\n",
    "\n",
    "        # Carrega o replay buffer do modelo treinado em simulação com 100k passos \n",
    "        replay_buffer_path = os.path.join(\"..\", \"models\", \"Abrupt Increase of BSW-simulated\", \"DQN\", \"replay_buffer\", \"dqn_save_replay_buffer.pkl\")\n",
    "        \n",
    "        # Retreina o modelo com o replay buffer do modelo treinado em simulação com 10k passos do modelo real\n",
    "        model_agent_cl = agente.env3W_dqn_cl(model_agent = model_agent, path_save=path_model, envs = envs_cl, \n",
    "                                             replaydir = replay_buffer_path, total_timesteps = 50000)\n",
    "        \n",
    "        # Avalia o modelo retreinado com 10k passos do ambiente real\n",
    "        logging.info(f'Iniciando avaliação do algoritmo DQN conjunto de teste (Continual Learning)')\n",
    "        accuracy = agente.env3W_dqn_eval(model = model_agent_cl, path_save=path_model)\n",
    "        print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando DQN (Continual Learning)')\n",
    "        logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando DQN (Continual Learning)')\n",
    "        logging.info(f'Fim avaliação  do algoritmo DQN conjunto de teste (Continual Learning)')   \n",
    "\n",
    "    # Para fechar explicitamente o arquivo de log, obtenha todos os handlers do root logger e feche-os\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        handler.close()\n",
    "        logging.root.removeHandler(handler)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração de gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Dados extraídos das imagens\n",
    "modelos = ['A2C', 'DQN', 'PPO']\n",
    "passos = np.array([1, 10, 100, 150, 300])  # Representando 10k passos de intervalo\n",
    "\n",
    "# Acurácia dos modelos com 10k em 10k passos, convertendo para porcentagem\n",
    "valores_DQN = np.array([0.29166, 0.72747, 0.92344, 0.93021, 0.94559]) * 100\n",
    "valores_PPO = np.array([0.50828, 0.80014, 0.86720, 0.90412, 0.89472]) * 100\n",
    "valores_A2C = np.array([0.49757, 0.49757, 0.77329, 0.77952, 0.80008]) * 100\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "# Plots para cada modelo\n",
    "plt.plot(passos, valores_DQN, marker='o', color='#F79646', label='DQN')\n",
    "plt.plot(passos, valores_PPO, marker='s', color='#C0504D', label='PPO')\n",
    "plt.plot(passos, valores_A2C, marker='^', color='#9C00A7', label='A2C')  # Alterado para melhor visibilidade\n",
    "\n",
    "# Personalizações\n",
    "plt.xlabel('Passos (milhares)')\n",
    "plt.ylabel('Acurácia (%)')\n",
    "plt.xticks(passos, rotation=45)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('..\\\\..\\\\img\\\\grafico_acuracia3.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Dados extraídos das imagens\n",
    "modelos = ['A2C', 'DQN', 'PPO']\n",
    "\n",
    "# Acurácia dos modelos com 10k em 10k passos\n",
    "valores_DQN = [0.7911,\n",
    "  0.87225,\n",
    "  0.9013,\n",
    "  0.87937,\n",
    "  0.92252,\n",
    "  0.91683,\n",
    "  0.93927,\n",
    "  0.9493,\n",
    "  0.88589,\n",
    "  0.94434,\n",
    "  0.50395,\n",
    "  0.93821,\n",
    "  0.90226,\n",
    "  0.81794,\n",
    "  0.88619,\n",
    "  0.84911,\n",
    "  0.62753,\n",
    "  0.71075,\n",
    "  0.9028,\n",
    "  0.95265,\n",
    "  0.91927,\n",
    "  0.88583,\n",
    "  0.9227,\n",
    "  0.92264,\n",
    "  0.93083,\n",
    "  0.94742,\n",
    "  0.95284,\n",
    "  0.94246,\n",
    "  0.94742,\n",
    "  0.94083]\n",
    "#[80.76, 88.11, 94, 91.53, 86.73, 94.24, 92.25, 94.84, 82.84, 90.07]\n",
    "valores_PPO = [0.74739,\n",
    "  0.79719,\n",
    "  0.8091,\n",
    "  0.40587,\n",
    "  0.81019,\n",
    "  0.76256,\n",
    "  0.40587,\n",
    "  0.75161,\n",
    "  0.80943,\n",
    "  0.80385,\n",
    "  0.81926,\n",
    "  0.79612,\n",
    "  0.8465,\n",
    "  0.78194,\n",
    "  0.81106,\n",
    "  0.39265,\n",
    "  0.39265,\n",
    "  0.39265,\n",
    "  0.3973,\n",
    "  0.433,\n",
    "  0.76758,\n",
    "  0.40685,\n",
    "  0.40168,\n",
    "  0.40472,\n",
    "  0.81062,\n",
    "  0.80889,\n",
    "  0.27819,\n",
    "  0.80542,\n",
    "  0.78754,\n",
    "  0.80283]\n",
    "#[80.51, 67.62, 81,  40.11, 40.49, 80.36, 79.21, 79.74, 77.66, 40.48]\n",
    "valores_A2C = accuracies = [\n",
    "    0.50870, 0.50730, 0.50440, 0.50704, 0.50900,\n",
    "    0.50388, 0.51218, 0.50802, 0.51214, 0.55713,\n",
    "    0.50500, 0.51191, 0.50919, 0.51024, 0.50741,\n",
    "    0.50582, 0.50376, 0.50029, 0.49884, 0.49658,\n",
    "    0.49522, 0.49387, 0.49241, 0.49095, 0.48950,\n",
    "    0.48804, 0.48659, 0.48513, 0.48368, 0.48223\n",
    "]\n",
    "\n",
    "# multiplicando por 100 para obter a porcentagem\n",
    "valores_DQN = [x * 100 for x in valores_DQN]\n",
    "valores_PPO = [x * 100 for x in valores_PPO]\n",
    "valores_A2C = [x * 100 for x in valores_A2C]\n",
    "\n",
    "\n",
    "#[50.25, 49.87, 50.47, 50.43, 51.19, 50.82, 50.42, 50.75, 51.26, 50.99]\n",
    "\n",
    "passos = np.arange(10, 301, 10)  # Representando 10k passos de intervalo, de 10k até 100k\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Plots para cada modelo\n",
    "plt.plot(passos, valores_DQN, marker='o', color='#F79646', label='DQN')\n",
    "plt.plot(passos, valores_PPO, marker='s', color='#C0504D', label='PPO')\n",
    "plt.plot(passos, valores_A2C, marker='^', color='#FF3399', label='A2C')\n",
    "\n",
    "# Adicionando rótulos, título e personalizando eixos\n",
    "plt.xlabel('Passos (em milhares)') # , fontweight='bold'\n",
    "plt.ylabel('Acurácia %') # , fontweight='bold'\n",
    "#plt.title('Comparação da Acurácia dos Modelos por Passos')\n",
    "plt.xticks(passos)\n",
    "plt.legend()\n",
    "# colocar em 45 graus\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('..\\\\..\\\\img\\\\grafico_acuracia2.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_names = {\n",
    "    # 0: 'Normal',\n",
    "    1: 'Abrupt Increase of BSW',\n",
    "    # 2: 'Spurious Closure of DHSV',\n",
    "    # 3: 'Severe Slugging',\n",
    "    # 4: 'Flow Instability',\n",
    "    # 5: 'Rapid Productivity Loss',\n",
    "    # 6: 'Quick Restriction in PCK',\n",
    "    # 7: 'Scaling in PCK',\n",
    "    # 8: 'Hydrate in Production Line'\n",
    "}\n",
    "\n",
    "event_name = [value for key, value in events_names.items() if key != 0][0]\n",
    "\n",
    "path_dataset = '..\\\\..\\\\..\\\\dataset'\n",
    "type_instance='real'\n",
    "\n",
    "instances = LoadInstances(path_dataset)\n",
    "            \n",
    "\n",
    "dataset, _ = instances.load_instance_with_numpy(events_names, type_instance=type_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2017-07-31 18:09:30', 44858050.0, 18373560.0, ..., 2538033.0,\n",
       "        78.87206, '0'],\n",
       "       ['2017-07-31 18:09:31', 44858050.0, 18373560.0, ..., 2538033.0,\n",
       "        78.87207, '0'],\n",
       "       ['2017-07-31 18:09:32', 44858050.0, 18373560.0, ..., 2538032.0,\n",
       "        78.87208, '0'],\n",
       "       ...,\n",
       "       ['2018-06-18 10:59:58', -1.180116e+42, 20647810.0, ...,\n",
       "        10138120.0, 71.27946, '1'],\n",
       "       ['2018-06-18 10:59:59', -1.180116e+42, 20647810.0, ...,\n",
       "        10138830.0, 71.27944, '1'],\n",
       "       ['2018-06-18 11:00:00', -1.180116e+42, 20647810.0, ...,\n",
       "        10139540.0, 71.27942, '1']], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "explora = exploration(pd.DataFrame(dataset, columns=['timestamp', 'P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'class']))\n",
    "\n",
    "explora.quartiles_plot(['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP'], f'Quartis das variáveis {type_instance} do evento {event_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
