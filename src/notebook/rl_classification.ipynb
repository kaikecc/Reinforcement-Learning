{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..'))\n",
    "from classes._LoadInstances import LoadInstances\n",
    "from classes._Env3WGym import Env3WGym\n",
    "from classes._Agent import Agent\n",
    "from classes._Supervised import Supervised\n",
    "from classes._ValidationModel import ValidationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação dos dados simulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_global_logger(logs_directory: str, event_name: str, type_instance: str, model_type: str) -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Configura e retorna um objeto de logger global.\n",
    "    Se já estiver configurado, retorna o mesmo objeto.\n",
    "    \n",
    "    O nome do arquivo de log seguirá o padrão:\n",
    "    '{directory}\\{current_time}_{event_name}-{type_instance}_{model_type}-log'\n",
    "    \"\"\"\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    log_filename = f'{current_time}_{event_name}-{type_instance}_{model_type}-log'\n",
    "    full_path = os.path.join(logs_directory, log_filename)\n",
    "    os.makedirs(logs_directory, exist_ok=True)\n",
    "    \n",
    "    logger = logging.getLogger(\"global_logger\")\n",
    "    if not logger.handlers:\n",
    "        logger.setLevel(logging.INFO)\n",
    "        handler = logging.FileHandler(full_path, mode='w', encoding='utf-8')\n",
    "        formatter = logging.Formatter(\n",
    "            '[%(levelname)s]\\t%(asctime)s - %(message)s',\n",
    "            datefmt='%d/%m/%Y %I:%M:%S %p'\n",
    "        )\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "def run_model_training_evaluation(agente: Agent, model_type: str, path_model: str,\n",
    "                                  list_timesteps: list, logger: logging.Logger,\n",
    "                                  supervised: Supervised = None) -> dict:\n",
    "    \"\"\"\n",
    "    Realiza o treinamento e avaliação do modelo conforme o tipo e retorna um dicionário\n",
    "    contendo 'accuracy' e 'model_agent' da última iteração bem-sucedida.\n",
    "    \"\"\"\n",
    "    final_result = None\n",
    "    for ts in list_timesteps:\n",
    "        agente.TIMESTEPS = ts\n",
    "        logger.info(f\"Iniciando treinamento do algoritmo {model_type} com {ts} timesteps\")\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            if model_type == 'DQN':\n",
    "                model_agent, _ = agente.env3W_dqn(path_save=path_model)\n",
    "            elif model_type == 'PPO':\n",
    "                model_agent = agente.env3W_ppo(path_save=path_model)\n",
    "            elif model_type == 'A2C':\n",
    "                model_agent = agente.env3W_a2c(path_save=path_model)\n",
    "            elif model_type == 'RNA':\n",
    "                model_agent = supervised.keras_train()\n",
    "            else:\n",
    "                raise ValueError(\"Modelo não implementado\")\n",
    "            train_time = round(time.time() - start_time, 2)\n",
    "            print(f\"Tempo de Treinamento {model_type}: {train_time}s\")\n",
    "            logger.info(f\"Tempo de Treinamento {model_type}: {train_time}s\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao treinar o modelo {model_type}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            logger.info(f\"Iniciando avaliação do algoritmo {model_type} no conjunto de teste\")\n",
    "            start_time = time.time()\n",
    "            if model_type == 'DQN':\n",
    "                accuracy = agente.env3W_dqn_eval(model=model_agent, path_save=path_model)\n",
    "            elif model_type == 'PPO':\n",
    "                accuracy = agente.env3W_ppo_eval(model=model_agent, path_save=path_model)\n",
    "            elif model_type == 'A2C':\n",
    "                accuracy = agente.env3W_a2c_eval(model=model_agent, path_save=path_model)\n",
    "            elif model_type == 'RNA':\n",
    "                accuracy = supervised.keras_evaluate(model_agent)\n",
    "            else:\n",
    "                raise ValueError(\"Modelo não implementado\")\n",
    "            eval_time = round(time.time() - start_time, 2)\n",
    "            print(f\"Acurácia: {accuracy * 100:.2f}% | Tempo de Avaliação: {eval_time}s\")\n",
    "            logger.info(f\"Acurácia: {accuracy:.5f}\")\n",
    "            final_result = {\"timesteps\": ts, \"model_agent\": model_agent, \"accuracy\": accuracy}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao avaliar o modelo {model_type}: {e}\")\n",
    "    return final_result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "\n",
    "    # Definição dos eventos (serão usados apenas os eventos com chave diferente de zero)\n",
    "    events_names = {\n",
    "        # 0: 'Normal',\n",
    "        1: 'Abrupt Increase of BSW',\n",
    "        # 2: 'Spurious Closure of DHSV',\n",
    "        # 3: 'Severe Slugging',\n",
    "        # 4: 'Flow Instability',\n",
    "        # 5: 'Rapid Productivity Loss',\n",
    "        # 6: 'Quick Restriction in PCK',\n",
    "        # 7: 'Scaling in PCK',\n",
    "        # 8: 'Hydrate in Production Line'       \n",
    "    }\n",
    "    # Para o tensorboard, utiliza o primeiro evento disponível\n",
    "    event_name_tensorboard = list(events_names.values())[0]\n",
    "\n",
    "    models = ['DQN']  # Opções: 'DQN', 'PPO', 'A2C', 'RNA'\n",
    "    type_instance = 'real'  # Alternativas: 'real', 'simulated'\n",
    "    path_dataset = os.path.join('..', '..', '..', 'dataset')\n",
    "    instances = LoadInstances(path_dataset)\n",
    "\n",
    "    # Configura o logger global com o padrão de nomenclatura solicitado\n",
    "    logs_directory = os.path.join('..', '..', 'logs')\n",
    "    # Utilizamos o primeiro modelo da lista para definir o nome do arquivo de log\n",
    "    model_type_for_log = models[0]\n",
    "    logger = get_global_logger(logs_directory, event_name_tensorboard, type_instance, model_type_for_log)\n",
    "    logger.info('Iniciando carregamento do dataset')\n",
    "    dataset, _ = instances.load_instance_with_numpy(events_names, type_instance=type_instance)\n",
    "    logger.info('Fim carregamento do dataset')\n",
    "\n",
    "    # Divisão do dataset em treino, teste e validação\n",
    "    train_percentage = 0.8\n",
    "    dataset_train_scaled, dataset_test_scaled, dataset_validation_scaled = instances.data_preparation(dataset, train_percentage)\n",
    "\n",
    "    # Configuração dos ambientes de treino e teste\n",
    "    env_train = Env3WGym(dataset_train_scaled, n_envs=5)\n",
    "    env_test = Env3WGym(dataset_test_scaled, n_envs=1)\n",
    "    envs_train = env_train.envs_random()\n",
    "    envs_test = env_test.envs_random()\n",
    "\n",
    "    # Diretório para salvar os modelos/tensorboard\n",
    "    path_tensorboard = os.path.join('..', 'models', f\"{event_name_tensorboard}-{type_instance}\")\n",
    "    os.makedirs(path_tensorboard, exist_ok=True)\n",
    "\n",
    "    # Instancia o agente com os ambientes configurados\n",
    "    agente = Agent(path_tensorboard, envs_train, envs_test, TIMESTEPS=1000)\n",
    "\n",
    "    list_timesteps = [100000]  # Exemplos: 1000, 10000, etc.\n",
    "\n",
    "    # Dicionário para armazenar os resultados finais de cada combinação (modelo, evento)\n",
    "    final_results = {}\n",
    "\n",
    "    for model_type in models:\n",
    "        for event_name in [value for key, value in events_names.items() if key != 0]:\n",
    "            # Cria os diretórios para os modelos (os logs já são gerenciados pelo logger global)\n",
    "            directory = os.path.join('..', '..', 'logs', f\"{event_name}-{type_instance}\")\n",
    "            path_model = os.path.join('..', 'models', f\"{event_name}-{type_instance}\", model_type)\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "            os.makedirs(path_model, exist_ok=True)\n",
    "\n",
    "            logger.info(f\"Iniciando execução do algoritmo {model_type}-{type_instance} para o evento {event_name} com timesteps {agente.TIMESTEPS}\")\n",
    "\n",
    "            # Para o modelo RNA, ajusta os rótulos e instancia o objeto supervised\n",
    "            if model_type == 'RNA':\n",
    "                dataset_train_scaled[:, -1] = np.where(dataset_train_scaled[:, -1] == 101, 1, dataset_train_scaled[:, -1])\n",
    "                dataset_test_scaled[:, -1] = np.where(dataset_test_scaled[:, -1] == 101, 1, dataset_test_scaled[:, -1])\n",
    "                supervised = Supervised(path_model, dataset_train_scaled, dataset_test_scaled)\n",
    "            else:\n",
    "                supervised = None\n",
    "\n",
    "            # Executa o treinamento e avaliação utilizando o logger global\n",
    "            result = run_model_training_evaluation(agente, model_type, path_model, list_timesteps, logger, supervised)\n",
    "            if result:\n",
    "                accuracy = result[\"accuracy\"]\n",
    "                model_agent = result[\"model_agent\"]\n",
    "                final_results[(model_type, event_name)] = result\n",
    "                print(f\"Final accuracy for {model_type} on event {event_name} with {result['timesteps']} timesteps: {accuracy*100:.2f}%\")\n",
    "                # As variáveis 'accuracy' e 'model_agent' estão disponíveis para uso posterior\n",
    "\n",
    "            logging.info(f'Iniciando a validação do modelo {model_type}') \n",
    "            validation = ValidationModel(model_type, event_name)\n",
    "            validation.validation_model(accuracy, dataset_validation_scaled, model_agent)\n",
    "\n",
    "            logging.info(f'Concluído a execução do algoritmo {model_type}-{type_instance} para o evento {event_name}')\n",
    "            # Para fechar explicitamente o arquivo de log, obtenha todos os handlers do root logger e feche-os\n",
    "            for handler in logging.root.handlers[:]:\n",
    "                handler.close()\n",
    "                logging.root.removeHandler(handler)\n",
    "\n",
    "    # Exemplo: acesso aos resultados armazenados\n",
    "    # print(final_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Iniciando a validação do modelo {model_type}') \n",
    "validation = ValidationModel(model_type, event_name)\n",
    "validation.validation_model(accuracy, dataset_validation_scaled, model_agent)\n",
    "\n",
    "logging.info(f'Concluído a execução do algoritmo {model_type}-{type_instance} para o evento {event_name}')\n",
    "# Para fechar explicitamente o arquivo de log, obtenha todos os handlers do root logger e feche-os\n",
    "for handler in logging.root.handlers[:]:\n",
    "    handler.close()\n",
    "    logging.root.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação com dados reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    events_names = {\n",
    "        # 0: 'Normal',\n",
    "        # 1: 'Abrupt Increase of BSW',\n",
    "        # 2: 'Spurious Closure of DHSV',\n",
    "         3: 'Severe Slugging',\n",
    "        # 4: 'Flow Instability',\n",
    "        # 5: 'Rapid Productivity Loss',\n",
    "        # 6: 'Quick Restriction in PCK',\n",
    "        # 7: 'Scaling in PCK',\n",
    "        # 8: 'Hydrate in Production Line'\n",
    "    }\n",
    "\n",
    "    event_name = [value for key, value in events_names.items() if key != 0][0]\n",
    "    \n",
    "    models = ['DQN'] # 'DQN' \n",
    "    type_instance= 'real' # real, simulated\n",
    "    path_dataset = '..\\\\..\\\\..\\\\dataset'\n",
    "    instances = LoadInstances(path_dataset)\n",
    "    model_type = models[0]\n",
    "            \n",
    "    logging.info(f'Iniciando carregamento do dataset')\n",
    "    dataset, _ = instances.load_instance_with_numpy(events_names, type_instance=type_instance)    \n",
    "    logging.info(f'Fim carregamento do dataset')    \n",
    "    \n",
    "    logging.info(f'Iniciando divisão do dataset em treino e teste')        \n",
    "    # Definindo a porcentagem para divisão entre treino e teste\n",
    "    train_percentage = 0.8  # 80% para treino\n",
    "    dataset_train_scaled, dataset_test_scaled, dataset_validation_scaled = instances.data_preparation(dataset, train_percentage)\n",
    "   \n",
    "    env_train = Env3WGym(dataset_train_scaled, n_envs = 5)\n",
    "    env_test = Env3WGym(dataset_test_scaled, n_envs = 1)\n",
    "\n",
    "    envs_train = env_train.envs_random()\n",
    "    envs_test = env_test.envs_random()\n",
    "\n",
    "    env_test_cl = Env3WGym(dataset_test_scaled, n_envs = 5)\n",
    "    envs_cl = env_test_cl.envs_random()\n",
    "\n",
    "    directory = f'..\\\\..\\\\logs\\\\{event_name}-{type_instance}-CL'\n",
    "    path_dataset = '..\\\\..\\\\..\\\\dataset'   \n",
    "    path_model = f'..\\\\models\\\\{event_name}-{type_instance}\\\\{model_type}'  \n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    if not os.path.exists(path_model):\n",
    "        os.makedirs(path_model)    \n",
    "\n",
    "    path_tensorboard = f'..\\\\models\\\\{event_name}-{type_instance}-CL'   \n",
    "    if not os.path.exists(path_tensorboard):\n",
    "        os.makedirs(path_tensorboard)\n",
    "\n",
    "    agente = Agent(path_tensorboard, envs_train, envs_test, TIMESTEPS = 100000)            \n",
    "\n",
    "            \n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    log_filename = f'{directory}\\\\{current_time}_{event_name}-{type_instance}_{model_type}-log.txt'\n",
    "    # Configuração do Logging\n",
    "    logging.basicConfig(filename=log_filename, filemode='w', level=logging.INFO, \n",
    "                        format='[%(levelname)s]\\t%(asctime)s - %(message)s', \n",
    "                        datefmt='%d/%m/%Y %I:%M:%S %p', force=True, encoding='utf-8')\n",
    "   \n",
    "\n",
    "    if model_type == 'DQN':\n",
    "        \n",
    "        logging.info(f'Iniciando o teste do algoritmo DQN (Continual Learning)')    \n",
    "        #start_time = time.time()\n",
    "        #model_agent = agente.env3W_dqn(path_save=path_model)  \n",
    "        #print(f\"Tempo de Treinamento DQN: {round(time.time() - start_time, 2)}s\")\n",
    "        #logging.info(f\"Tempo de Treinamento DQN: {round(time.time() - start_time, 2)}s\")\n",
    "        #logging.info(f'Fim treinamento do algoritmo DQN')\n",
    "        \n",
    "\n",
    "        # Carrega o modelo treinado em simulação com 100k passos\n",
    "        path_model_zip = os.path.join(\"..\", \"models\", \"Abrupt Increase of BSW-simulated\", \"DQN\", \"_DQN.zip\")\n",
    "        \n",
    "        # Avalia o modelo treinado em simulação com 100k passos no ambiente real\n",
    "        model_agent = DQN.load(path_model_zip) \n",
    "        logging.info(f'Iniciando avaliação do algoritmo DQN conjunto de teste')\n",
    "        accuracy = agente.env3W_dqn_eval(model = model_agent, path_save=path_model)\n",
    "        print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando DQN')\n",
    "        logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando DQN')\n",
    "        logging.info(f'Fim avaliação  do algoritmo DQN conjunto de teste')\n",
    "\n",
    "        # Carrega o replay buffer do modelo treinado em simulação com 100k passos \n",
    "        replay_buffer_path = os.path.join(\"..\", \"models\", \"Abrupt Increase of BSW-simulated\", \"DQN\", \"replay_buffer\", \"dqn_save_replay_buffer.pkl\")\n",
    "        \n",
    "        # Retreina o modelo com o replay buffer do modelo treinado em simulação com 10k passos do modelo real\n",
    "        model_agent_cl = agente.env3W_dqn_cl(model_agent = model_agent, path_save=path_model, envs = envs_cl, \n",
    "                                             replaydir = replay_buffer_path, total_timesteps = 50000)\n",
    "        \n",
    "        # Avalia o modelo retreinado com 10k passos do ambiente real\n",
    "        logging.info(f'Iniciando avaliação do algoritmo DQN conjunto de teste (Continual Learning)')\n",
    "        accuracy = agente.env3W_dqn_eval(model = model_agent_cl, path_save=path_model)\n",
    "        print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando DQN (Continual Learning)')\n",
    "        logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando DQN (Continual Learning)')\n",
    "        logging.info(f'Fim avaliação  do algoritmo DQN conjunto de teste (Continual Learning)')   \n",
    "\n",
    "    # Para fechar explicitamente o arquivo de log, obtenha todos os handlers do root logger e feche-os\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        handler.close()\n",
    "        logging.root.removeHandler(handler)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração de gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_names = {\n",
    "    1: 'Normal',\n",
    "    #2: 'Abrupt Increase of BSW',\n",
    "    #3: 'Spurious Closure of DHSV',\n",
    "    #4: 'Severe Slugging',\n",
    "    #5: 'Flow Instability',\n",
    "    #6: 'Rapid Productivity Loss',\n",
    "    #7: 'Quick Restriction in PCK',\n",
    "    #8: 'Scaling in PCK',\n",
    "    #9: 'Hydrate in Production Line'\n",
    "}\n",
    "\n",
    "\n",
    "path_dataset = '..\\\\..\\\\..\\\\dataset'\n",
    "type_instance = 'real'\n",
    "\n",
    "# Initialize instances\n",
    "instances = LoadInstances(path_dataset)\n",
    "\n",
    "# Load the dataset\n",
    "dataset, _ = instances.load_instance_with_numpy(events_names, type_instance=type_instance) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'dataset' is your numpy array\n",
    "df = pd.DataFrame(dataset, columns=['timestamp', 'P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'class'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name = 'Spurious Closure of DHSV'\n",
    "\n",
    "explora = exploration(pd.DataFrame(dataset, columns=['timestamp', 'P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'class']))\n",
    "\n",
    "#explora.quartiles_plot(['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP'], f'Quartis das variáveis {type_instance} do evento {event_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name = 'Normal'\n",
    "\n",
    "explora.heatmap_corr(['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP'], f'Correlação das variáveis {type_instance} do evento {event_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the attribute for plotting\n",
    "attribute = 'P-PDG'\n",
    "\n",
    "# Extract the data for the selected attribute and filter by\n",
    "\n",
    "attribute_data = df[attribute].dropna()\n",
    "\n",
    "# Plotting the density plot for the selected attribute\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=attribute_data, fill=True, label=f\"{attribute}\")\n",
    "plt.title(f'Density Plot for the dataset - {attribute}')\n",
    "plt.xlabel(attribute)\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "# Plotting density plots as subplots for specified columns\n",
    "attributes = ['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP']\n",
    "# Creating density plots in a grid layout (3 columns) with distinct colors\n",
    "colors = ['blue', 'green', 'red', 'orange', 'purple']\n",
    "n_cols = 3\n",
    "n_rows = -(-len(attributes) // n_cols)  # Ceiling division to get the number of rows\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(15, 10))\n",
    "\n",
    "axes = axes.flatten()  # Flatten to simplify indexing\n",
    "\n",
    "for i, attribute in enumerate(attributes):\n",
    "    attribute_data = df[attribute].astype(float)\n",
    "    density = gaussian_kde(attribute_data)\n",
    "    x_vals = np.linspace(attribute_data.min(), attribute_data.max(), 1000)\n",
    "    density_vals = density(x_vals)\n",
    "    \n",
    "    # Plotting each density\n",
    "    axes[i].plot(x_vals, density_vals, color=colors[i % len(colors)], label=attribute)\n",
    "    axes[i].fill_between(x_vals, density_vals, color=colors[i % len(colors)], alpha=0.3)\n",
    "    #axes[i].set_title(f'Density Plot: {attribute}')\n",
    "    axes[i].set_xlabel(attribute)\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].legend()\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(len(attributes), len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
