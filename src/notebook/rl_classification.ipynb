{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.dqn.policies import MlpPolicy\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from datetime import datetime\n",
    "from torch import nn  # Import the neural network module from PyTorch\n",
    "import gym\n",
    "from gym import spaces\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.dqn.policies import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import sys\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "import os\n",
    "sys.path.append(os.path.join('..'))\n",
    "from classes._exploration import exploration\n",
    "from classes._Env3WGym import Env3WGym\n",
    "from classes._LoadInstances import LoadInstances\n",
    "from classes._Agent import Agent\n",
    "from classes._Supervised import Supervised\n",
    "from classes._ValidationModel import ValidationModel\n",
    "from classes._exploration import exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação dos dados simulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras da classe 0: 684000\n",
      "Número de amostras da classe 1: 2872713\n",
      "Número de amostras da classe 101: 4766400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para visualizar os logs do TensorBoard, execute:\n",
      "tensorboard --logdir='..\\models\\Abrupt Increase of BSW-simulated\\tensorboard_logs'\n",
      "Using cpu device\n",
      "Logging to ..\\models\\Abrupt Increase of BSW-simulated\\tensorboard_logs\\A2C_0\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3510     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.229   |\n",
      "|    explained_variance | -0.103   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.00255  |\n",
      "|    value_loss         | 1.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3630     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.156   |\n",
      "|    explained_variance | 0.102    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.00775 |\n",
      "|    value_loss         | 0.734    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3700     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.115   |\n",
      "|    explained_variance | 0.268    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.0162   |\n",
      "|    value_loss         | 0.571    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3761     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0857  |\n",
      "|    explained_variance | 0.0654   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.0421   |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "Logging to ..\\models\\Abrupt Increase of BSW-simulated\\tensorboard_logs\\A2C_0\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 4207     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.101   |\n",
      "|    explained_variance | 0.0484   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.061   |\n",
      "|    value_loss         | 1.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3948     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0139  |\n",
      "|    explained_variance | 0.0608   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.00016 |\n",
      "|    value_loss         | 0.853    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3998     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.088   |\n",
      "|    explained_variance | 0.0444   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.0252   |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 4050     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.118   |\n",
      "|    explained_variance | 0.295    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.0161   |\n",
      "|    value_loss         | 0.356    |\n",
      "------------------------------------\n",
      "Logging to ..\\models\\Abrupt Increase of BSW-simulated\\tensorboard_logs\\A2C_0\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 4010     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.054   |\n",
      "|    explained_variance | 0.0297   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.0255   |\n",
      "|    value_loss         | 0.944    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 4009      |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0616   |\n",
      "|    explained_variance | -0.0908   |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -0.000591 |\n",
      "|    value_loss         | 0.38      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 4040      |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0465   |\n",
      "|    explained_variance | -0.224    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -0.000678 |\n",
      "|    value_loss         | 0.324     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 4069     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0622  |\n",
      "|    explained_variance | 0.202    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.00118  |\n",
      "|    value_loss         | 0.288    |\n",
      "------------------------------------\n",
      "Logging to ..\\models\\Abrupt Increase of BSW-simulated\\tensorboard_logs\\A2C_0\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 4047     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0776  |\n",
      "|    explained_variance | 0.0214   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.0358   |\n",
      "|    value_loss         | 0.803    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3861     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0503  |\n",
      "|    explained_variance | 0.0218   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.00348 |\n",
      "|    value_loss         | 0.893    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 3865      |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0428   |\n",
      "|    explained_variance | 0.113     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -0.000935 |\n",
      "|    value_loss         | 0.791     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3937     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0243  |\n",
      "|    explained_variance | 0.0801   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.00558  |\n",
      "|    value_loss         | 0.551    |\n",
      "------------------------------------\n",
      "Logging to ..\\models\\Abrupt Increase of BSW-simulated\\tensorboard_logs\\A2C_0\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 4154     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.03    |\n",
      "|    explained_variance | 0.197    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.00107 |\n",
      "|    value_loss         | 1.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 4170     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0418  |\n",
      "|    explained_variance | 0.145    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.00552 |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 4138      |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000743 |\n",
      "|    explained_variance | 0.229     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -4.4e-06  |\n",
      "|    value_loss         | 1.05      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 4107      |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00278  |\n",
      "|    explained_variance | 0.135     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -3.79e-05 |\n",
      "|    value_loss         | 0.483     |\n",
      "-------------------------------------\n",
      "Logging to ..\\models\\Abrupt Increase of BSW-simulated\\tensorboard_logs\\A2C_0\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 4057     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0259  |\n",
      "|    explained_variance | 0.158    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.00378  |\n",
      "|    value_loss         | 1.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 4025     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0189  |\n",
      "|    explained_variance | 0.123    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.00128  |\n",
      "|    value_loss         | 0.326    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 4051      |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00773  |\n",
      "|    explained_variance | 0.314     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -0.000571 |\n",
      "|    value_loss         | 1.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 4045     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0884  |\n",
      "|    explained_variance | 0.204    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.00786  |\n",
      "|    value_loss         | 0.439    |\n",
      "------------------------------------\n",
      "Logging to ..\\models\\Abrupt Increase of BSW-simulated\\tensorboard_logs\\A2C_0\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3515     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0515  |\n",
      "|    explained_variance | 0.0442   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.00487  |\n",
      "|    value_loss         | 0.628    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3562     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0481  |\n",
      "|    explained_variance | -0.0356  |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.0461  |\n",
      "|    value_loss         | 1.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3372     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0878  |\n",
      "|    explained_variance | -0.048   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.01    |\n",
      "|    value_loss         | 0.462    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3403     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0224  |\n",
      "|    explained_variance | 0.0239   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.0128  |\n",
      "|    value_loss         | 1.22     |\n",
      "------------------------------------\n",
      "Logging to ..\\models\\Abrupt Increase of BSW-simulated\\tensorboard_logs\\A2C_0\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 3704      |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0118   |\n",
      "|    explained_variance | 0.127     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -0.000395 |\n",
      "|    value_loss         | 0.732     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 3824      |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00427  |\n",
      "|    explained_variance | 0.215     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -0.000102 |\n",
      "|    value_loss         | 0.703     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3863     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0077  |\n",
      "|    explained_variance | 0.266    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.00141 |\n",
      "|    value_loss         | 0.95     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 3909     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0245  |\n",
      "|    explained_variance | 0.226    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.0091  |\n",
      "|    value_loss         | 0.393    |\n",
      "------------------------------------\n",
      "Logging to ..\\models\\Abrupt Increase of BSW-simulated\\tensorboard_logs\\A2C_0\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 4233     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0189  |\n",
      "|    explained_variance | -0.133   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.00315  |\n",
      "|    value_loss         | 0.836    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 4172      |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000614 |\n",
      "|    explained_variance | 0.179     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -7.89e-05 |\n",
      "|    value_loss         | 0.587     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 4047      |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000246 |\n",
      "|    explained_variance | 0.0715    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 8.28e-06  |\n",
      "|    value_loss         | 0.643     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 4098      |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000252 |\n",
      "|    explained_variance | 0.1       |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -1.11e-05 |\n",
      "|    value_loss         | 1.12      |\n",
      "-------------------------------------\n",
      "Tempo de Treinamento A2C: 25.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para visualizar os logs do TensorBoard, execute:\n",
      "tensorboard --logdir='..\\models\\Abrupt Increase of BSW-simulated\\tensorboard_logs'\n",
      "Acurácia de 84.92% no conjunto de dados de teste usando A2C\n",
      "Acurácia final: 91.897% no conjunto de dados de validação\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    events_names = {\n",
    "        # 0: 'Normal',\n",
    "        1: 'Abrupt Increase of BSW',\n",
    "        # 2: 'Spurious Closure of DHSV',\n",
    "        # 3: 'Severe Slugging',\n",
    "        # 4: 'Flow Instability',\n",
    "        # 5: 'Rapid Productivity Loss',\n",
    "        # 6: 'Quick Restriction in PCK',\n",
    "        # 7: 'Scaling in PCK',\n",
    "        # 8: 'Hydrate in Production Line'\n",
    "    }\n",
    "\n",
    "    event_name = [value for key, value in events_names.items() if key != 0][0]\n",
    "    \n",
    "    models = ['A2C'] # 'DQN' or 'PPO', 'RNA', 'A2C'\n",
    "    type_instance='simulated'\n",
    "\n",
    "    for model_type in models:\n",
    "        for event_name in [value for key, value in events_names.items() if key != 0]:\n",
    "\n",
    "            directory = f'..\\\\..\\\\logs\\\\{event_name}-{type_instance}'\n",
    "            path_dataset = '..\\\\..\\\\..\\\\dataset'   \n",
    "            path_model = f'..\\\\models\\\\{event_name}-{type_instance}\\\\{model_type}'  \n",
    "\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            \n",
    "            if not os.path.exists(path_model):\n",
    "                os.makedirs(path_model)                \n",
    "            \n",
    "                    \n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            log_filename = f'{directory}\\\\{current_time}_{event_name}-{type_instance}_{model_type}-log.txt'\n",
    "            # Configuração do Logging\n",
    "            logging.basicConfig(filename=log_filename, filemode='w', level=logging.INFO, format='[%(levelname)s]\\t%(asctime)s - %(message)s', datefmt='%d/%m/%Y %I:%M:%S %p', force=True, encoding='utf-8')\n",
    "\n",
    "            instances = LoadInstances(path_dataset)\n",
    "            \n",
    "            logging.info(f'Iniciando carregamento do dataset')\n",
    "            dataset, _ = instances.load_instance_with_numpy(events_names, type_instance=type_instance)    \n",
    "            logging.info(f'Fim carregamento do dataset')\n",
    "            \n",
    "            logging.info(f'Iniciando divisão do dataset em treino e teste')\n",
    "                \n",
    "            # Definindo a porcentagem para divisão entre treino e teste\n",
    "            train_percentage = 0.8  # 80% para treino\n",
    "\n",
    "            dataset_train_scaled, dataset_test_scaled, dataset_validation_scaled = instances.data_preparation(dataset, train_percentage)\n",
    "\n",
    "            if model_type == 'DQN':\n",
    "                logging.info(f'Iniciando treinamento do algoritmo DQN')    \n",
    "                start_time = time.time()\n",
    "                agente = Agent(path_model)\n",
    "                model_agent, replaydir = agente.env3W_dqn(dataset_train_scaled, n_envs = 5)  \n",
    "                print(f\"Tempo de Treinamento DQN: {round(time.time() - start_time, 2)}s\")\n",
    "                logging.info(f\"Tempo de Treinamento DQN: {round(time.time() - start_time, 2)}s\")\n",
    "                logging.info(f'Fim treinamento do algoritmo DQN')\n",
    "\n",
    "\n",
    "                logging.info(f'Iniciando avaliação do algoritmo DQN conjunto de teste')\n",
    "                accuracy = agente.env3W_dqn_eval(dataset_test_scaled, model_agent, n_envs = 1)\n",
    "                print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando DQN')\n",
    "                logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando DQN')\n",
    "                logging.info(f'Fim avaliação  do algoritmo DQN conjunto de teste')\n",
    "                \n",
    "            elif model_type == 'PPO':      \n",
    "                logging.info(f'Iniciando treinamento do algoritmo PPO') \n",
    "                start_time = time.time()\n",
    "                agente = Agent(path_model)\n",
    "                model_agent = agente.env3W_ppo(dataset_train_scaled, n_envs = 5)  \n",
    "                print(f\"Tempo de Treinamento PPO: {round(time.time() - start_time, 2)}s\")\n",
    "                logging.info(f\"Tempo de Treinamento PPO: {round(time.time() - start_time, 2)}s\")\n",
    "                logging.info(f'Fim treinamento do algoritmo PPO')\n",
    "\n",
    "                logging.info(f'Iniciando avaliação do algoritmo PPO conjunto de teste')\n",
    "                accuracy = agente.env3W_ppo_eval(dataset_test_scaled, model_agent, n_envs = 1)\n",
    "                print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando PPO')\n",
    "                logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando PPO')\n",
    "                logging.info(f'Fim avaliação  do algoritmo PPO conjunto de teste')\n",
    "\n",
    "            elif model_type == 'A2C':      \n",
    "                logging.info(f'Iniciando treinamento do algoritmo A2C') \n",
    "                start_time = time.time()\n",
    "                agente = Agent(path_model)\n",
    "                model_agent = agente.env3W_a2c(dataset_train_scaled, n_envs = 5)  \n",
    "                print(f\"Tempo de Treinamento A2C: {round(time.time() - start_time, 2)}s\")\n",
    "                logging.info(f\"Tempo de Treinamento A2C: {round(time.time() - start_time, 2)}s\")\n",
    "                logging.info(f'Fim treinamento do algoritmo A2C')\n",
    "\n",
    "                logging.info(f'Iniciando avaliação do algoritmo A2C conjunto de teste')\n",
    "                accuracy = agente.env3W_a2c_eval(dataset_test_scaled, model_agent, n_envs = 1)\n",
    "                print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando A2C')\n",
    "                logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando A2C')\n",
    "                logging.info(f'Fim avaliação  do algoritmo A2C conjunto de teste')\n",
    "            \n",
    "            elif model_type == 'RNA':\n",
    "                logging.info(f'Iniciando treinamento do modelo RNA') \n",
    "                supervised = Supervised(path_model, dataset_train_scaled, dataset_test_scaled)\n",
    "                start_time = time.time()\n",
    "                model_agent = supervised.keras_train()  \n",
    "                print(f\"Tempo de Treinamento RNA: {round(time.time() - start_time, 2)}s\")\n",
    "                logging.info(f\"Tempo de Treinamento RNA: {round(time.time() - start_time, 2)}s\")\n",
    "                logging.info(f'Fim treinamento do modelo RNA')\n",
    "\n",
    "                logging.info(f'Iniciando avaliação do modelo RNA conjunto de teste')\n",
    "                accuracy = supervised.keras_evaluate(model_agent)\n",
    "                print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando RNA')\n",
    "                logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando RNA')\n",
    "                logging.info(f'Fim avaliação  do modelo RNA conjunto de teste')\n",
    "\n",
    "            logging.info(f'Iniciando a validação do modelo {model_type}') \n",
    "            validation = ValidationModel(model_type, event_name)\n",
    "\n",
    "            validation.validation_model(accuracy, dataset_validation_scaled, model_agent)\n",
    "\n",
    "            logging.info(f'Concluído a execução do algoritmo {model_type}-{type_instance} para o evento {event_name}')\n",
    "    # Para fechar explicitamente o arquivo de log, obtenha todos os handlers do root logger e feche-os\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        handler.close()\n",
    "        logging.root.removeHandler(handler)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação com dados reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    events_names = {\n",
    "        # 0: 'Normal',\n",
    "        1: 'Abrupt Increase of BSW',\n",
    "        # 2: 'Spurious Closure of DHSV',\n",
    "        # 3: 'Severe Slugging',\n",
    "        # 4: 'Flow Instability',\n",
    "        # 5: 'Rapid Productivity Loss',\n",
    "        # 6: 'Quick Restriction in PCK',\n",
    "        # 7: 'Scaling in PCK',\n",
    "        # 8: 'Hydrate in Production Line'\n",
    "    }\n",
    "\n",
    "    event_name = [value for key, value in events_names.items() if key != 0][0]\n",
    "    \n",
    "    models = ['DQN'] # 'DQN' or 'PPO', 'RNA', 'A2C'\n",
    "    type_instance='real'\n",
    "\n",
    "    for model_type in models:\n",
    "        for event_name in [value for key, value in events_names.items() if key != 0]:\n",
    "\n",
    "            directory = f'..\\\\..\\\\logs\\\\{event_name}-{type_instance}'\n",
    "            path_dataset = '..\\\\..\\\\..\\\\dataset'   \n",
    "            path_model = f'..\\\\models\\\\{event_name}-{type_instance}\\\\{model_type}'  \n",
    "\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            \n",
    "            if not os.path.exists(path_model):\n",
    "                os.makedirs(path_model)                \n",
    "            \n",
    "                    \n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            log_filename = f'{directory}\\\\{current_time}_{event_name}-{type_instance}_{model_type}-log.txt'\n",
    "            # Configuração do Logging\n",
    "            logging.basicConfig(filename=log_filename, filemode='w', level=logging.INFO, format='[%(levelname)s]\\t%(asctime)s - %(message)s', datefmt='%d/%m/%Y %I:%M:%S %p', force=True, encoding='utf-8')\n",
    "\n",
    "            instances = LoadInstances(path_dataset)\n",
    "            \n",
    "            logging.info(f'Iniciando carregamento do dataset')\n",
    "            dataset, _ = instances.load_instance_with_numpy(events_names, type_instance=type_instance)    \n",
    "            logging.info(f'Fim carregamento do dataset')\n",
    "            \n",
    "            logging.info(f'Iniciando divisão do dataset em treino e teste')\n",
    "                \n",
    "            # Definindo a porcentagem para divisão entre treino e teste\n",
    "            train_percentage = 0.8  # 80% para treino\n",
    "\n",
    "            dataset_train_scaled, dataset_test_scaled, dataset_validation_scaled = instances.data_preparation(dataset, train_percentage)\n",
    "\n",
    "            if model_type == 'DQN':\n",
    "                #logging.info(f'Iniciando treinamento do algoritmo DQN')    \n",
    "                #start_time = time.time()\n",
    "                agente = Agent(path_model)\n",
    "                #model_agent = agente.env3W_dqn(dataset_train_scaled, n_envs = 5)  \n",
    "                #print(f\"Tempo de Treinamento DQN: {round(time.time() - start_time, 2)}s\")\n",
    "                #logging.info(f\"Tempo de Treinamento DQN: {round(time.time() - start_time, 2)}s\")\n",
    "                #logging.info(f'Fim treinamento do algoritmo DQN')\n",
    "\n",
    "                model_agent = DQN.load(f\"{path_model.replace('real', 'simulated')}\\_DQN_Env3W\") \n",
    "                logging.info(f'Iniciando avaliação do algoritmo DQN conjunto de teste')\n",
    "                accuracy = agente.env3W_dqn_eval(dataset_test_scaled, model_agent, n_envs = 1)\n",
    "                print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando DQN')\n",
    "                logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando DQN')\n",
    "                logging.info(f'Fim avaliação  do algoritmo DQN conjunto de teste')\n",
    "                \n",
    "                #replay_buffer_path = os.path.join(\"..\", \"models\", \"Abrupt Increase of BSW-simulated\", \"DQN\") # , \"replay_buffer\"\n",
    "                logging.info(f'Iniciando treinamento do algoritmo DQN (Continual Learning)')\n",
    "                model_agent_cl = agente.env3W_dqn_cl(model_agent, dataset_test_scaled, replaydir = replaydir, n_envs = 5)\n",
    "                logging.info(f'Iniciando avaliação do algoritmo DQN conjunto de teste (Continual Learning)')\n",
    "                accuracy = agente.env3W_dqn_eval(dataset_test_scaled, model_agent_cl, n_envs = 1)\n",
    "                print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando DQN (Continual Learning)')\n",
    "                logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando DQN (Continual Learning)')\n",
    "                logging.info(f'Fim avaliação  do algoritmo DQN conjunto de teste (Continual Learning)')\n",
    "                \n",
    "                \n",
    "            elif model_type == 'PPO':      \n",
    "            \n",
    "                #start_time = time.time()\n",
    "                agente = Agent(path_model)\n",
    "                #model_agent = agente.env3W_ppo(dataset_train_scaled, n_envs = 5)  \n",
    "                #print(f\"Tempo de Treinamento PPO: {round(time.time() - start_time, 2)}s\")\n",
    "                #logging.info(f\"Tempo de Treinamento PPO: {round(time.time() - start_time, 2)}s\")\n",
    "                #logging.info(f'Fim treinamento do algoritmo PPO')\n",
    "\n",
    "                \n",
    "                model_agent = PPO.load(f\"{path_model.replace('real', 'simulated')}\\_PPO_Env3W\")\n",
    "                logging.info(f'Iniciando avaliação do algoritmo PPO conjunto de teste')\n",
    "                accuracy = agente.env3W_ppo_eval(dataset_test_scaled, model_agent, n_envs = 1)\n",
    "                print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando PPO')\n",
    "                logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando PPO')\n",
    "                logging.info(f'Fim avaliação  do algoritmo PPO conjunto de teste')\n",
    "\n",
    "            elif model_type == 'A2C':      \n",
    "            \n",
    "                #start_time = time.time()\n",
    "                agente = Agent(path_model)\n",
    "                #model_agent = agente.env3W_a2c(dataset_train_scaled, n_envs = 5)  \n",
    "                #print(f\"Tempo de Treinamento A2C: {round(time.time() - start_time, 2)}s\")\n",
    "                #logging.info(f\"Tempo de Treinamento A2C: {round(time.time() - start_time, 2)}s\")\n",
    "                #logging.info(f'Fim treinamento do algoritmo A2C')\n",
    "\n",
    "                model_agent = A2C.load(f\"{path_model.replace('real', 'simulated')}/_A2C_Env3W\")\n",
    "\n",
    "                logging.info(f'Iniciando avaliação do algoritmo A2C conjunto de teste')\n",
    "                accuracy = agente.env3W_a2c_eval(dataset_test_scaled, model_agent, n_envs = 1)\n",
    "                print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando A2C')\n",
    "                logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando A2C')\n",
    "                logging.info(f'Fim avaliação  do algoritmo A2C conjunto de teste')\n",
    "            \n",
    "            elif model_type == 'RNA':\n",
    "                #logging.info(f'Iniciando treinamento do modelo RNA')  \n",
    "                \n",
    "                supervised = Supervised(os.path.dirname(path_model.replace('real', 'simulated')), dataset_train_scaled, dataset_test_scaled)\n",
    "                #start_time = time.time()\n",
    "                #model_agent = supervised.keras_train()  \n",
    "                #print(f\"Tempo de Treinamento RNA: {round(time.time() - start_time, 2)}s\")\n",
    "                #logging.info(f\"Tempo de Treinamento RNA: {round(time.time() - start_time, 2)}s\")\n",
    "                #logging.info(f'Fim treinamento do modelo RNA')\n",
    "                \n",
    "                model_agent = supervised.keras_load_model(\"RNA_Env3W\") # Reinforcement-Learning\\src\\models\\Abrupt Increase of BSW-simulated\\RNA_Env3W\n",
    "                \n",
    "                logging.info(f'Iniciando avaliação do modelo RNA conjunto de teste')\n",
    "                accuracy = supervised.keras_evaluate(model_agent)\n",
    "                print(f'Acurácia de {accuracy * 100:.2f}% no conjunto de dados de teste usando RNA')\n",
    "                logging.info(f'Acurácia de {accuracy:.5f} no conjunto de dados de teste usando RNA')\n",
    "                logging.info(f'Fim avaliação  do modelo RNA conjunto de teste')\n",
    "\n",
    "            #logging.info(f'Iniciando a validação do modelo {model_type}') \n",
    "            validation = ValidationModel(model_type, event_name)\n",
    "\n",
    "            validation.validation_model(accuracy, dataset_validation_scaled, model_agent)\n",
    "\n",
    "            logging.info(f'Concluído a execução do algoritmo {model_type}-{type_instance} para o evento {event_name}')\n",
    "\n",
    "    # Para fechar explicitamente o arquivo de log, obtenha todos os handlers do root logger e feche-os\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        handler.close()\n",
    "        logging.root.removeHandler(handler)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''events_names = {\n",
    "    # 0: 'Normal',\n",
    "    1: 'Abrupt Increase of BSW',\n",
    "    # 2: 'Spurious Closure of DHSV',\n",
    "    # 3: 'Severe Slugging',\n",
    "    # 4: 'Flow Instability',\n",
    "    # 5: 'Rapid Productivity Loss',\n",
    "    # 6: 'Quick Restriction in PCK',\n",
    "    # 7: 'Scaling in PCK',\n",
    "    # 8: 'Hydrate in Production Line'\n",
    "}\n",
    "\n",
    "event_name = [value for key, value in events_names.items() if key != 0][0]\n",
    "\n",
    "\n",
    "type_instance='simulated'\n",
    "\n",
    "instances = LoadInstances(path_dataset)\n",
    "            \n",
    "\n",
    "dataset, _ = instances.load_instance_with_numpy(events_names, type_instance=type_instance)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''explora = exploration(pd.DataFrame(dataset, columns=['timestamp', 'P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'class']))\n",
    "\n",
    "explora.quartiles_plot(['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP'], f'Quartis das variáveis {type_instance} do evento {event_name}')'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
