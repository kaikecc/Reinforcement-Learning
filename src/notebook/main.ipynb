{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importação e Configuração do 3W Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Patch\n",
    "from pathlib import Path\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from collections import defaultdict\n",
    "from natsort import natsorted\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data_path = Path('/home/dataset')\n",
    "\n",
    "events_names = {0: 'Normal',\n",
    "                1: 'Abrupt Increase of BSW',\n",
    "                2: 'Spurious Closure of DHSV',\n",
    "                3: 'Severe Slugging',\n",
    "                4: 'Flow Instability',\n",
    "                5: 'Rapid Productivity Loss',\n",
    "                6: 'Quick Restriction in PCK',\n",
    "                7: 'Scaling in PCK',\n",
    "                8: 'Hydrate in Production Line'\n",
    "               }\n",
    "columns = ['P-PDG',\n",
    "           'P-TPT',\n",
    "           'T-TPT',\n",
    "           'P-MON-CKP',\n",
    "           'T-JUS-CKP',\n",
    "           'P-JUS-CKGL',\n",
    "           'T-JUS-CKGL',\n",
    "           'QGL',\n",
    "           'class']\n",
    "rare_threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_and_file_generator(data_path, real=False, simulated=False, drawn=False):\n",
    "    for class_path in data_path.iterdir():\n",
    "        if class_path.is_dir():\n",
    "            try:\n",
    "                class_code = int(class_path.stem)\n",
    "            except ValueError:\n",
    "                # Se não for possível converter para int, pule este diretório\n",
    "                continue\n",
    "            \n",
    "            for instance_path in class_path.iterdir():\n",
    "                if (instance_path.suffix == '.csv'):\n",
    "                    if (simulated and instance_path.stem.startswith('SIMULATED')) or \\\n",
    "                       (drawn and instance_path.stem.startswith('DRAWN')) or \\\n",
    "                       (real and (not instance_path.stem.startswith('SIMULATED')) and \\\n",
    "                       (not instance_path.stem.startswith('DRAWN'))):\n",
    "                        yield class_code, instance_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_instances = list(class_and_file_generator(data_path, real=True, simulated=False, drawn=False))\n",
    "simulated_instances = list(class_and_file_generator(data_path, real=False, simulated=True, drawn=False))\n",
    "drawn_instances = list(class_and_file_generator(data_path, real=False, simulated=False, drawn=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of real instances: 1019\n",
      "Number of simulated instances: 939\n",
      "Number of drawn instances: 20\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of real instances: {len(real_instances)}')\n",
    "print(f'Number of simulated instances: {len(simulated_instances)}')\n",
    "print(f'Number of drawn instances: {len(drawn_instances)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>well</th>\n",
       "      <th>id</th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>P-JUS-CKGL</th>\n",
       "      <th>T-JUS-CKGL</th>\n",
       "      <th>QGL</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-26 08:01:46</th>\n",
       "      <td>4</td>\n",
       "      <td>WELL-00002</td>\n",
       "      <td>20140126080146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16166470.0</td>\n",
       "      <td>117.6411</td>\n",
       "      <td>6317682.0</td>\n",
       "      <td>173.0961</td>\n",
       "      <td>4217536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-26 08:01:47</th>\n",
       "      <td>4</td>\n",
       "      <td>WELL-00002</td>\n",
       "      <td>20140126080146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16166140.0</td>\n",
       "      <td>117.6411</td>\n",
       "      <td>6329183.0</td>\n",
       "      <td>173.0961</td>\n",
       "      <td>4217533.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-26 08:01:48</th>\n",
       "      <td>4</td>\n",
       "      <td>WELL-00002</td>\n",
       "      <td>20140126080146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16165810.0</td>\n",
       "      <td>117.6410</td>\n",
       "      <td>6340685.0</td>\n",
       "      <td>173.0961</td>\n",
       "      <td>4217530.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-26 08:01:49</th>\n",
       "      <td>4</td>\n",
       "      <td>WELL-00002</td>\n",
       "      <td>20140126080146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16165470.0</td>\n",
       "      <td>117.6409</td>\n",
       "      <td>6352186.0</td>\n",
       "      <td>173.0961</td>\n",
       "      <td>4217527.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-26 08:01:50</th>\n",
       "      <td>4</td>\n",
       "      <td>WELL-00002</td>\n",
       "      <td>20140126080146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16165140.0</td>\n",
       "      <td>117.6408</td>\n",
       "      <td>6363688.0</td>\n",
       "      <td>173.0961</td>\n",
       "      <td>4217523.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label        well              id  P-PDG       P-TPT  \\\n",
       "timestamp                                                                   \n",
       "2014-01-26 08:01:46      4  WELL-00002  20140126080146    0.0  16166470.0   \n",
       "2014-01-26 08:01:47      4  WELL-00002  20140126080146    0.0  16166140.0   \n",
       "2014-01-26 08:01:48      4  WELL-00002  20140126080146    0.0  16165810.0   \n",
       "2014-01-26 08:01:49      4  WELL-00002  20140126080146    0.0  16165470.0   \n",
       "2014-01-26 08:01:50      4  WELL-00002  20140126080146    0.0  16165140.0   \n",
       "\n",
       "                        T-TPT  P-MON-CKP  T-JUS-CKP  P-JUS-CKGL  T-JUS-CKGL  \\\n",
       "timestamp                                                                     \n",
       "2014-01-26 08:01:46  117.6411  6317682.0   173.0961   4217536.0         NaN   \n",
       "2014-01-26 08:01:47  117.6411  6329183.0   173.0961   4217533.0         NaN   \n",
       "2014-01-26 08:01:48  117.6410  6340685.0   173.0961   4217530.0         NaN   \n",
       "2014-01-26 08:01:49  117.6409  6352186.0   173.0961   4217527.0         NaN   \n",
       "2014-01-26 08:01:50  117.6408  6363688.0   173.0961   4217523.0         NaN   \n",
       "\n",
       "                     QGL  class  \n",
       "timestamp                        \n",
       "2014-01-26 08:01:46  0.0      4  \n",
       "2014-01-26 08:01:47  0.0      4  \n",
       "2014-01-26 08:01:48  0.0      4  \n",
       "2014-01-26 08:01:49  0.0      4  \n",
       "2014-01-26 08:01:50  0.0      4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_instance(instances):\n",
    "    class_code, instance_path = instances\n",
    "    try:\n",
    "        well, instance_id = instance_path.stem.split('_')\n",
    "        df = pd.read_csv(instance_path, index_col='timestamp', parse_dates=['timestamp'])\n",
    "        assert (df.columns == columns).all(), \"invalid columns in the file {}: {}\".format(str(instance_path), str(df.columns.tolist()))\n",
    "        df['label'] = class_code\n",
    "        df['well'] = well\n",
    "        df['id'] = instance_id\n",
    "        df = df[['label', 'well', 'id'] + columns]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise Exception('error reading file {}: {}'.format(instance_path, e))\n",
    "    \n",
    "\n",
    "df = load_instance(real_instances[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SOURCE</th>\n",
       "      <th>DRAWN</th>\n",
       "      <th>REAL</th>\n",
       "      <th>SIMULATED</th>\n",
       "      <th>TOTAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TYPE OF EVENT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 - Normal</th>\n",
       "      <td>0</td>\n",
       "      <td>594</td>\n",
       "      <td>0</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 - Abrupt Increase of BSW</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 - Spurious Closure of DHSV</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 - Severe Slugging</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>74</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 - Flow Instability</th>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 - Rapid Productivity Loss</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>439</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 - Quick Restriction in PCK</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>215</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 - Scaling in PCK</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 - Hydrate in Production Line</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>20</td>\n",
       "      <td>1019</td>\n",
       "      <td>939</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "SOURCE                          DRAWN  REAL  SIMULATED  TOTAL\n",
       "TYPE OF EVENT                                                \n",
       "0 - Normal                          0   594          0    594\n",
       "1 - Abrupt Increase of BSW         10     5        114    129\n",
       "2 - Spurious Closure of DHSV        0    22         16     38\n",
       "3 - Severe Slugging                 0    32         74    106\n",
       "4 - Flow Instability                0   344          0    344\n",
       "5 - Rapid Productivity Loss         0    11        439    450\n",
       "6 - Quick Restriction in PCK        0     6        215    221\n",
       "7 - Scaling in PCK                 10     5          0     15\n",
       "8 - Hydrate in Production Line      0     0         81     81\n",
       "TOTAL                              20  1019        939   1978"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "\n",
    "# Supondo que real_instances, simulated_instances, drawn_instances e events_names já estejam definidos\n",
    "instances_class = [{'TYPE OF EVENT': str(c) + ' - ' + events_names[c], 'SOURCE': 'REAL'} for c, p in real_instances] + \\\n",
    "                  [{'TYPE OF EVENT': str(c) + ' - ' + events_names[c], 'SOURCE': 'SIMULATED'} for c, p in simulated_instances] + \\\n",
    "                  [{'TYPE OF EVENT': str(c) + ' - ' + events_names[c], 'SOURCE': 'DRAWN'} for c, p in drawn_instances]\n",
    "df_class = pd.DataFrame(instances_class)\n",
    "\n",
    "# Correção aqui: pivot(index, columns, values) com argumentos nomeados\n",
    "df_class_count = df_class.groupby(['TYPE OF EVENT', 'SOURCE']).size().reset_index(name='count')\n",
    "df_class_count = df_class_count.pivot(index='TYPE OF EVENT', columns='SOURCE', values='count').fillna(0).astype(int)\n",
    "\n",
    "# Transposição não é necessária após a correção, mas ajustaremos a orientação conforme sua intenção original\n",
    "#df_class_count = df_class_count.T\n",
    "\n",
    "# Ordenação natural dos índices, se necessário\n",
    "df_class_count = df_class_count.loc[natsorted(df_class_count.index)]\n",
    "\n",
    "# Reordenar colunas se 'REAL', 'SIMULATED', 'DRAWN' estiverem presentes, adicionando a coluna 'TOTAL'\n",
    "df_class_count['TOTAL'] = df_class_count.sum(axis=1)\n",
    "df_class_count.loc['TOTAL'] = df_class_count.sum(axis=0)\n",
    "\n",
    "# Exibindo o DataFrame final\n",
    "df_class_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação de um único dataframe com todos os poços reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14516197 entries, 0 to 14516196\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   label       int64  \n",
      " 1   well        object \n",
      " 2   id          object \n",
      " 3   P-PDG       float64\n",
      " 4   P-TPT       float64\n",
      " 5   T-TPT       float64\n",
      " 6   P-MON-CKP   float64\n",
      " 7   T-JUS-CKP   float64\n",
      " 8   P-JUS-CKGL  float64\n",
      " 9   T-JUS-CKGL  float64\n",
      " 10  QGL         float64\n",
      " 11  class       float64\n",
      "dtypes: float64(9), int64(1), object(2)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Carregar todos os DataFrames dos arquivos de instâncias reais\n",
    "df_all_instances_real = [pd.DataFrame(load_instance(instance)) for instance in real_instances]\n",
    "\n",
    "# Concatenar todos os DataFrames na lista para formar um único DataFrame\n",
    "df = pd.concat(df_all_instances_real, ignore_index=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação de um dataframe para o desenvolvimento de um Ambiente Python (TF)\n",
    "\n",
    "Critério de seleção dos poços\n",
    "\n",
    "1. Com mais de três tipos de eventos: 'WELL-00001', 'WELL-00002', 'WELL-00004', 'WELL-00006'\n",
    "2. Dois poços para equilibrar a falta de eventos: 'WELL-00015', 'WELL-00016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9645620 entries, 0 to 14484284\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   P-PDG      float64\n",
      " 1   P-TPT      float64\n",
      " 2   T-TPT      float64\n",
      " 3   P-MON-CKP  float64\n",
      " 4   T-JUS-CKP  float64\n",
      " 5   class      float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 515.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Lista de poços para treinamento do modelo\n",
    "wells_to_include = ['WELL-00001', 'WELL-00002', 'WELL-00004', 'WELL-00006', 'WELL-00015', 'WELL-00016']\n",
    "\n",
    "# Selecionando colunas específicas\n",
    "columns_to_select = ['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'class']\n",
    "\n",
    "# Filtrando o DataFrame para incluir apenas os poços desejados e colunas específicas, e removendo linhas com NaNs\n",
    "df_env = df[df['well'].isin(wells_to_include)][columns_to_select].dropna()\n",
    "\n",
    "# Mostrando informações do DataFrame filtrado\n",
    "df_env.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-PDG        0\n",
      "P-TPT        0\n",
      "T-TPT        0\n",
      "P-MON-CKP    0\n",
      "T-JUS-CKP    0\n",
      "class        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_env.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np  # Ensure numpy is imported\n",
    "\n",
    "def quartiles_plot(df, sensors, title):\n",
    "    # Ensure 'class' values are in the correct format, avoiding inplace=True\n",
    "    df['class'] = df['class'].fillna('-1')  # Fill NaN and directly assign\n",
    "    df['class'] = df['class'].astype(float).astype(int).astype(str)  # Convert types as before\n",
    "    \n",
    "    base_colors = {'Normal': 'lightgreen', 'Estável de Anomalia': 'lightcoral', 'Transiente de Anomalia': 'lightyellow', 'Não Rotulado': 'lightgrey'}\n",
    "    legend_class = {\n",
    "        '0': 'Normal', \n",
    "        '-1': 'Não Rotulado',\n",
    "        **{str(i): 'Estável de Anomalia' for i in range(1, 9)},\n",
    "        **{str(100 + i): 'Transiente de Anomalia' for i in range(1, 9)}\n",
    "    }\n",
    "    \n",
    "    class_colors = {cls: base_colors[label] for cls, label in legend_class.items()}\n",
    "    unique_labels = np.unique(list(legend_class.values()))\n",
    "    patches = [mpatches.Patch(color=base_colors[label], label=label) for label in unique_labels]\n",
    "    \n",
    "    class_counts = df['class'].value_counts()\n",
    "    top_classes = class_counts.nlargest(100).index\n",
    "    filtered_data = df[df['class'].isin(top_classes)]\n",
    "    \n",
    "    n_vars = len(sensors)\n",
    "    ncols = 2\n",
    "    nrows = int(np.ceil(n_vars / ncols))\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(12, 6 * nrows), squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, var in enumerate(sensors):\n",
    "        class_palette = {cls: class_colors.get(cls, 'gray') for cls in filtered_data['class'].unique()}\n",
    "        sns.boxplot(x='class', y=var, data=filtered_data, ax=axes[i], palette=class_palette, showfliers=False)\n",
    "        axes[i].set_title(f'Distribuição de {var} por Classificação')\n",
    "        axes[i].set_xlabel('Classificação')\n",
    "        axes[i].set_ylabel('Pressão (Pa)' if var in ['P-PDG', 'P-TPT', 'P-MON-CKP'] else 'Temperatura (°C)')\n",
    "        axes[i].tick_params(axis='x', rotation=0)\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    for j in range(i + 1, nrows * ncols):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    quartiles_results = {}\n",
    "    for var in sensors:\n",
    "        quartiles_results[var] = {}\n",
    "        for cls in filtered_data['class'].unique():\n",
    "            data = filtered_data[filtered_data['class'] == cls][var]\n",
    "            quartiles = data.quantile([0.25, 0.5, 0.75]).to_dict()\n",
    "            quartiles_results[var][cls] = quartiles\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.figlegend(handles=patches, loc='upper center', bbox_to_anchor=(0.5, 0.05), ncol=4, title='Classificação')\n",
    "    plt.subplots_adjust(bottom=0.15, top=0.95)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df_test = df_env.sample(frac=0.2, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Make sure `df_env` and `columns_to_select` are defined before calling quartiles_plot\n",
    "quartiles_plot(df_test, columns_to_select, 'Boxplot - Sensores de Pressão/Temperatura')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento dos dados do dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.195413</td>\n",
       "      <td>-0.063940</td>\n",
       "      <td>0.178590</td>\n",
       "      <td>0.367639</td>\n",
       "      <td>3.059375</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.195413</td>\n",
       "      <td>-0.063941</td>\n",
       "      <td>0.178590</td>\n",
       "      <td>0.370626</td>\n",
       "      <td>3.059375</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195413</td>\n",
       "      <td>-0.063943</td>\n",
       "      <td>0.178576</td>\n",
       "      <td>0.373613</td>\n",
       "      <td>3.059375</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.195413</td>\n",
       "      <td>-0.063944</td>\n",
       "      <td>0.178562</td>\n",
       "      <td>0.376600</td>\n",
       "      <td>3.059375</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.195413</td>\n",
       "      <td>-0.063946</td>\n",
       "      <td>0.178547</td>\n",
       "      <td>0.379587</td>\n",
       "      <td>3.059375</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      P-PDG     P-TPT     T-TPT  P-MON-CKP  T-JUS-CKP  class\n",
       "0  0.195413 -0.063940  0.178590   0.367639   3.059375      4\n",
       "1  0.195413 -0.063941  0.178590   0.370626   3.059375      4\n",
       "2  0.195413 -0.063943  0.178576   0.373613   3.059375      4\n",
       "3  0.195413 -0.063944  0.178562   0.376600   3.059375      4\n",
       "4  0.195413 -0.063946  0.178547   0.379587   3.059375      4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colunas para normalizar, exceto 'class'\n",
    "columns_to_normalize = ['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP']\n",
    "\n",
    "# Aplicando Z-score Standardization\n",
    "df_env[columns_to_normalize] = (df_env[columns_to_normalize] - df_env[columns_to_normalize].mean()) / df_env[columns_to_normalize].std()\n",
    "\n",
    "# Converte a coluna 'class' para valor int\n",
    "df_env['class'] = df_env['class'].astype(int)\n",
    "\n",
    "# Verifique as primeiras linhas para confirmar a normalização\n",
    "df_env.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..'))\n",
    "from classes._env3W import env3W  # Ajuste para o caminho correto da sua classe de ambiente\n",
    "\n",
    "import reverb\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiperparâmentros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações iniciais\n",
    "num_iterations = 20000  # ou mais, dependendo da complexidade do ambiente\n",
    "\n",
    "initial_collect_steps = 1000  # Número de passos de coleta inicial\n",
    "collect_steps_per_iteration = 1  # Passos de coleta por iteração de treinamento\n",
    "replay_buffer_max_length = 100000  # Tamanho máximo do replay buffer\n",
    "\n",
    "log_interval = 1000  # Log do progresso a cada 1000 iterações de treinamento\n",
    "eval_interval = 5000  # Avaliação do desempenho do agente a cada 5000 iterações\n",
    "batch_size = 64  # Exemplo de tamanho de batch para treinamento\n",
    "num_iterations = 10000  # Exemplo de número de iterações de treinamento\n",
    "learning_rate= 1e-3 # Taxa de aprendizado\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambiente\n",
    "\n",
    "No Aprendizado por Reforço (RL), um ambiente representa a tarefa ou problema a ser resolvido. Ambientes padrão podem ser criados em TF-Agents usando conjuntos tf_agents.environments.\n",
    "\n",
    "1. O ambiente é um repositório di github https://github.com/petrobras/3W\n",
    "2. O ambiente é composto por dados de seis poços de petróleo, com cinco variáveis (observações) de entrada ['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP'] e um rótulo indentificador de falha [class]\n",
    "3. O ambiente é um ambiente de simulação, onde o agente pode escolher entre duas ações: 0 - Não Detectado ou 1 - Detectado para cada observação\n",
    "4. A recompensa é calculada com base na ação escolhida e no rótulo de falha [class]:\n",
    "\n",
    "Estados:\n",
    "- rótulo de falha: 0 - Estado Normal\n",
    "- rótulo de falha: 1 a 8 - Estável de Anomalia (Falha)\n",
    "- rótulo de falha: 101 a 108 - Transiente de Anomalia (Falha)\n",
    "\n",
    "Ações/Recompensas:\n",
    "- Se o rótulo de falha for 0, a recompensa é 1 se a ação for 0, caso contrário, a recompensa é -100\n",
    "- Se o rótulo de falha estiver entre 1 e 8, a recompensa é -100 se a ação for 0, caso contrário, a recompensa é 100\n",
    "- Se o rótulo de falha estiver entre 101 e 108, a recompensa é -10 se a ação for 0, caso contrário, a recompensa é 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amostra aleatória de 20% dos dados \n",
    "df_test = df_env.sample(frac=0.2, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Criação do ambiente de teste\n",
    "env = env3W(df_test)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para validar o ambiente, é usado uma política aleatória para gerar ações e faremos a iteração em mais de 5 episódios para garantir que as coisas estejam funcionando como pretendido. Um erro é gerado se recebermos um time_step que não segue as especificações do ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "utils.validate_py_environment(env, episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa o método reset para iniciar o ambiente\n",
    "time_step = env.reset()\n",
    "print(\"Estado Inicial:\", time_step)\n",
    "\n",
    "# Executa algumas ações para testar a resposta do ambiente\n",
    "for _ in range(5):\n",
    "    action = np.random.randint(0, 2)  # Escolhe uma ação aleatória, 0 ou 1\n",
    "    time_step = env.step(action)\n",
    "    print(\"Após a ação:\", action, \"Time Step:\", time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No ambiente env3W:\n",
    "\n",
    "* Observação é um array de cinco floats:\n",
    "\n",
    "    * Três sensores de pressão: 'P-PDG', 'P-TPT', 'P-MON-CKP'\n",
    "    * Dois sensores de temperatura: 'T-TPT', T-JUS-CKP'\n",
    "\n",
    "* A recompensa é um escalar inteiro.\n",
    "\n",
    "* A ação é um escalar inteiro com duas possibilidades:\n",
    "\n",
    "    * 0 — \"Não Detectado\"\n",
    "    * 1 — \"Detectado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:')\n",
    "print(time_step)\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente dois ambientes são instanciados: um para treinamento e outro para avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = tf_py_environment.TFPyEnvironment(env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(env)  # Avaliação pode ser em um env similar ou diferente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agente\n",
    "\n",
    "O algoritmo utilizado para resolver um problema de RL é representado por um Agente. TF-Agents fornece implementações padrão de uma variedade de Agentes, incluindo:\n",
    "\n",
    "* DQN (Usado para teste)\n",
    "* REINFORCE\n",
    "* DDPG\n",
    "* TD3\n",
    "* PPO\n",
    "* SAC\n",
    "\n",
    "O agente DQN pode ser utilizado em qualquer ambiente que possua um espaço de ação discreto.\n",
    "\n",
    "No coração de um Agente DQN está uma QNetwork, um modelo de rede neural que pode aprender a prever QValues (retornos esperados) para todas as ações, dada uma observação do ambiente.\n",
    "\n",
    "Usaremos tf_agents.networks. para criar uma QNetwork. A rede será composta por uma sequência de camadas tf.keras.layers.Dense, onde a camada final terá 1 saída para cada ação possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, 50)  # Exemplo de tamanho das camadas totalmente conectadas\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Defina uma função auxiliar para criar camadas densas configuradas com o direito\n",
    "# ativação e inicializador do kernel.\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "\n",
    "# QNetwork consiste em uma sequência de camadas densas seguidas por uma camada densa\n",
    "# com unidades `num_actions` para gerar um q_value por ação disponível como sua saída.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora use tf_agents.agents.dqn.dqn_agent para instanciar um DqnAgent. Além de time_step_spec, action_spec e QNetwork, o construtor do agente também requer um otimizador (neste caso, AdamOptimizer), uma função de perda e um contador de passos inteiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Política\n",
    "\n",
    "Uma política define a forma como um agente atua em um ambiente. Normalmente, o objetivo da aprendizagem por reforço é treinar o modelo subjacente até que a política produza o resultado desejado.\n",
    "\n",
    "* O resultado desejado é a identificar uma falha com base nas observações\n",
    "* A política retorna uma ação (Não Detectado ou Detectado) para cada observação time_step.\n",
    "\n",
    "Os agentes contêm duas políticas:\n",
    "\n",
    "* agent.policy — A política principal usada para avaliação e implantação.\n",
    "* agent.collect_policy — Uma segunda política usada para coleta de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As políticas podem ser criadas independentemente dos agentes. Por exemplo, use tf_agents.policies.random_tf_policy para criar uma política que selecionará aleatoriamente uma ação para cada time_step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obter uma ação de uma política, chame o método policy.action(time_step). O time_step contém a observação do ambiente. Este método retorna um PolicyStep, que é uma tupla nomeada com três componentes:\n",
    "\n",
    "* ação - a ação a ser executada (neste caso, 0 ou 1)\n",
    "* estado – usado para políticas com estado (isto é, baseadas em ANN)\n",
    "* info — dados auxiliares, como log de probabilidades de ações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "time_step = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.policies import random_tf_policy\n",
    "\n",
    "# Exemplo de criação de uma política aleatória\n",
    "# Supondo que env seja seu ambiente TF-Agents\n",
    "random_policy = random_tf_policy.RandomTFPolicy(action_spec=env.action_spec(),\n",
    "                                                 time_step_spec=env.time_step_spec())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas e Avaliação\n",
    "\n",
    "A métrica mais comum usada para avaliar uma política é o retorno médio. O retorno é a soma das recompensas obtidas durante a execução de uma política em um ambiente durante um episódio. Vários episódios são executados, criando um retorno médio.\n",
    "\n",
    "A função a seguir calcula o retorno médio de uma política, dada a política, o ambiente e um número de episódios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@test {\"skip\": true}\n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A execução desse cálculo em random_policy mostra um desempenho de linha de base no ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Buffer\n",
    "\n",
    "Para acompanhar os dados coletados do ambiente, usaremos o Reverb, um sistema de replay eficiente, extensível e fácil de usar da Deepmind. Ele armazena dados de experiência quando coletamos trajetórias e são consumidos durante o treinamento.\n",
    "\n",
    "Este buffer de reprodução é construído usando especificações que descrevem os tensores que devem ser armazenados, que podem ser obtidos do agente usando agent.collect_data_spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'uniform_table'\n",
    "replay_buffer_signature = tensor_spec.from_spec(\n",
    "      agent.collect_data_spec)\n",
    "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "    replay_buffer_signature)\n",
    "\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=replay_buffer_max_length,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    "    signature=replay_buffer_signature)\n",
    "\n",
    "reverb_server = reverb.Server([table])\n",
    "\n",
    "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    table_name=table_name,\n",
    "    sequence_length=2,\n",
    "    local_server=reverb_server)\n",
    "\n",
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "  replay_buffer.py_client,\n",
    "  table_name,\n",
    "  sequence_length=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a maioria dos agentes, collect_data_spec é uma tupla nomeada chamada Trajetória, contendo especificações para observações, ações, recompensas e outros itens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.collect_data_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.collect_data_spec._fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleção de dados\n",
    "\n",
    "Agora execute a política aleatória no ambiente por algumas etapas, registrando os dados no buffer de reprodução.\n",
    "\n",
    "Aqui estamos usando 'PyDriver' para executar o ciclo de coleta de experiência. Você pode aprender mais sobre o driver TF Agents em nosso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@test {\"skip\": true}\n",
    "py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      random_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=initial_collect_steps).run(env.reset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O buffer de repetição agora é uma coleção de trajetórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the curious:\n",
    "# Uncomment to peel one of these off and inspect it.\n",
    "# iter(replay_buffer.as_dataset()).next()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O agente precisa de acesso ao buffer de reprodução. Isso é fornecido pela criação de um pipeline tf.data.Dataset iterável que alimentará os dados para o agente.\n",
    "\n",
    "Cada linha do buffer de reprodução armazena apenas uma única etapa de observação. Mas como o Agente DQN precisa da observação atual e da próxima para calcular a perda, o pipeline do conjunto de dados irá amostrar duas linhas adjacentes para cada item no lote (num_steps=2).\n",
    "\n",
    "Este conjunto de dados também é otimizado executando chamadas paralelas e pré-busca de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando o agente\n",
    "\n",
    "Duas coisas devem acontecer durante o ciclo de treinamento:\n",
    "\n",
    "* coletar dados do ambiente\n",
    "* usar esses dados para treinar a(s) rede(s) neural(is) do agente\n",
    "\n",
    "Este exemplo também avalia periodicamente a política e imprime a pontuação atual.\n",
    "\n",
    "O seguinte levará cerca de 5 minutos para ser executado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@test {\"skip\": true}\n",
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step.\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "# Reset the environment.\n",
    "time_step = env.reset()\n",
    "\n",
    "# Create a driver to collect experience.\n",
    "collect_driver = py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      agent.collect_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=collect_steps_per_iteration)\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps and save to the replay buffer.\n",
    "  time_step, _ = collect_driver.run(time_step)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience).loss\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
